## Negative Log-likelyhood
The negative log-likelihood loss function is often used in combination with a SoftMax activation function to define how well your neural network classifies data.
L(y)=-ln(y)
This is summed for all the correct classes.
